
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Surrogate-based optimisation with polynomials &#8212; equadratures</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/eq-logo-favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Modules" href="modules.html" />
    <link rel="prev" title="Polynomial variable projection" href="tutorial_12.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <img src="../_static/logo_new.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">equadratures</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="tutorials.html">Tutorials</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="modules.html">Modules</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="references.html">Research</a>
        </li>
        
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discourse.equadratures.org/">Discourse<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>


      <form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search equadratures..." aria-label="Search equadratures..." autocomplete="off" >
</form>
      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/Effective-Quadratures/equadratures" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
          <li class="nav-item">
            <a class="nav-link" href="https://twitter.com/equadratures" target="_blank" rel="noopener">
              <span><i class="fab fa-twitter-square"></i></span>
            </a>
          </li>
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
          
            
  
                <li class="active">
                    <a href="tutorials.html">Tutorials</a>
                    <ul>
                    
                        <li class="">
                            <a href="tutorial_1.html">Foundations I</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_2.html">Foundations II</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_3.html">Foundations III</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_4.html">Uncertainty quantification in computational fluid dynamics</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_5.html">Multi-index sets</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_6.html">Polynomial regression</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_7.html">Bayesian polynomial regression</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_8.html">Sparse and tensor grid quadrature rules</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_9.html">Computing Sobol’ (sensitivity) indices</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_11.html">Active subspaces with polynomial approximations</a>
                        </li>
                    
                        <li class="">
                            <a href="tutorial_12.html">Polynomial variable projection</a>
                        </li>
                    
                        <li class="active">
                            <a href="">Surrogate-based optimisation with polynomials</a>
                        </li>
                    
                    </ul>
                </li>
            
          
            
                <li class="">
                    <a href="modules.html">Modules</a>
                </li>
            
          
            
                <li class="">
                    <a href="references.html">Research</a>
                </li>
            
          
        
        
        
          
            
                <li class="">
                    <a href="tutorial_1.html">Foundations I</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_2.html">Foundations II</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_3.html">Foundations III</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_4.html">Uncertainty quantification in computational fluid dynamics</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_5.html">Multi-index sets</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_6.html">Polynomial regression</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_7.html">Bayesian polynomial regression</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_8.html">Sparse and tensor grid quadrature rules</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_9.html">Computing Sobol’ (sensitivity) indices</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_11.html">Active subspaces with polynomial approximations</a>
                </li>
            
          
            
                <li class="">
                    <a href="tutorial_12.html">Polynomial variable projection</a>
                </li>
            
          
            
                <li class="active">
                    <a href="">Surrogate-based optimisation with polynomials</a>
                </li>
            
          
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="surrogate-based-optimisation-with-polynomials">
<h1>Surrogate-based optimisation with polynomials<a class="headerlink" href="#surrogate-based-optimisation-with-polynomials" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we demonstrate how one may use orthogonal polynomials constructed in Effective Quadratures for surrogate-based optimisation. One particularly significant benefit of using orthogonal polynomials for optimisation is that the polynomial basis terms <span class="math notranslate nohighlight">\(\psi_{i}\)</span> and their derivatives <span class="math notranslate nohighlight">\(\psi_{i}^{(d)}\)</span> may be easily found using the standard four-term recurrence</p>
<div class="math notranslate nohighlight">
\[\sqrt{\beta_{i+1}} \psi_{i+1}^{(d)} = (r-\alpha_i) \psi_i^{(d)} - \sqrt{\beta_i} \psi_{i-1}^{(d)} + d \psi_i^{(d-1)}\]</div>
<p>for <span class="math notranslate nohighlight">\(d,i \geq 0\)</span> where <span class="math notranslate nohighlight">\(\psi_i^{(d)} \equiv 0\)</span> for <span class="math notranslate nohighlight">\(n &lt; d, n &lt; 0\)</span>. The recurrence coefficients <span class="math notranslate nohighlight">\(\alpha_i, \beta_i\)</span>, whose values are determined by the user-specified distribution of the weight function, indicate the class of orthogonal polynomial <span class="math notranslate nohighlight">\(\psi_{i}\)</span>. Using this recurrence relation, derivatives of all orders may be calculated by Effective Quadratures very efficiently, allowing the user to have easy access to gradient information for optimisation of orthogonal polynomials. Effective Quadratures has a built-in <code class="code docutils literal notranslate"><span class="pre">Optimisation</span></code> class that will calculate derivatives of orthogonal polynomials and perform optimisation using the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">minimize</a> method from <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.html">Scipy optimize</a>. Also included in this class is a simple derivative-free trust-region method for bound-constrained optimisation of nonlinear functions. This trust-region implementation constructs interpolating quadratic models using a set of <span class="math notranslate nohighlight">\(\frac{(n+1)(n+1)}{2}\)</span> points.</p>
<p>To demonstrate a simple example of how this class can be used for surrogate-based optimisation, we consider the following constrained optimisation problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\min_{x,y}      \quad           &amp; (1-x)^2 + 100(y-x^2)^2        \\
\textrm{ subject to }   &amp; x^3 - y \leq 0        \\
                                                &amp; x + y = 2                             \\
                                                &amp; -1 \leq x \leq 1                      \\
                                                &amp; -1 \leq y \leq 1.
\end{eqnarray}\end{split}\]</div>
<p>First, let’s use <code class="code docutils literal notranslate"><span class="pre">Poly</span></code> to construct the objective function and the first constraint in terms of Legendre polynomials defined over a total order basis.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">equadratures</span> <span class="k">as</span> <span class="nn">eq</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">linregress</span>

<span class="k">def</span> <span class="nf">ObjFun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">rosen</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">g1</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1">#Evaluate the objective and constraint functions over a random DOE</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">ObjFun</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">ConFun1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#Split data into training and testing data</span>
<span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
<span class="n">num_training_instances</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">train_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">num_training_instances</span><span class="p">]</span>
<span class="n">test_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">num_training_instances</span><span class="p">:]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">f_train</span><span class="p">,</span> <span class="n">g1_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">,</span> <span class="p">:],</span> <span class="n">f</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">g1</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">f_test</span><span class="p">,</span> <span class="n">g1_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_indices</span><span class="p">,</span> <span class="p">:],</span> <span class="n">f</span><span class="p">[</span><span class="n">test_indices</span><span class="p">],</span> <span class="n">g1</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
<span class="c1">#Construct f using Legendre polynomials with a total order basis</span>
<span class="n">fParameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">fpoly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">fParameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X_train</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">f_train</span><span class="p">})</span>
<span class="n">fpoly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>
<span class="c1">#Construct g1 using Legendre polynomials with a total order basis</span>
<span class="n">g1Parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">g1poly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">g1Parameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X_train</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">g1_train</span><span class="p">})</span>
<span class="n">g1poly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>
</pre></div>
</div>
<p>The coefficient of determination (R-squared) value of the fit of both of these functions can be computed via:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">r_f</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">fpoly</span><span class="o">.</span><span class="n">get_polyfit</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">f_test</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">r_g1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">g1poly</span><span class="o">.</span><span class="n">get_polyfit</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">g1_test</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">r_f</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r_g1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Both of these functions very nearly give a fit of <span class="math notranslate nohighlight">\(1.0\)</span>, indicating an almost exact fit.</p>
<div class="figure align-default" id="id1">
<a class="reference internal image-reference" href="../_images/Rosenbrock.png"><img alt="../_images/Rosenbrock.png" src="../_images/Rosenbrock.png" style="width: 581.4px; height: 386.4px;" /></a>
<p class="caption"><span class="caption-text">Figure. Contours of the objective function.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Now that the nonlinear functions have been constructed using orthogonal polynomials, we can use <code class="code docutils literal notranslate"><span class="pre">Optimisation</span></code> to solve the aforementioned optimisation problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Initialise optimisation problem by specifying optimisation method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Optimisation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g1poly &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;poly&#39;</span><span class="p">:</span> <span class="n">g1poly</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]})</span>
<span class="c1">#Add linear equality constraints Ax = b</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_linear_eq_con</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="c1">#Add lower and upper bounds</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_bounds</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="c1">#Initialise starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimisation problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimise</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The solution to the above surrogate-based optimisation problem is dependent on the points which are used to train the model. However, the solution will very closely responds to the true optimal solution of <span class="math notranslate nohighlight">\(0\)</span> found at <span class="math notranslate nohighlight">\(x = [1,1]\)</span>.</p>
<p>Alternatively, if one already has access to function and derivatives values for a quantity of interest, one may not need to construct a <code class="code docutils literal notranslate"><span class="pre">Poly</span></code> object for the function. In these cases, user-provided functions may be supplied to the optimisation routine. The following code demonstrates how to do this for the first constraint of the same optimisation problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ConFun1_Deriv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">ConFun1_Hess</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g_Hess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">g_Hess</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">6.0</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">g_Hess</span>

<span class="c1">#Construct lambda functions of the constraint, its derivative, and its Hessian</span>
<span class="n">g1Func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">g1Grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1_Deriv</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="n">g1Hess</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1_Hess</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="c1">#Initialise optimisation problem by specifying optimization method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Optimisation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add lower and upper bounds</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_bounds</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="c1">#Add linear equality constraints Ax = b</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_linear_eq_con</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g1Func &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">custom</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;function&#39;</span><span class="p">:</span> <span class="n">g1Func</span><span class="p">,</span> <span class="s1">&#39;jac_function&#39;</span><span class="p">:</span> <span class="n">g1Grad</span><span class="p">,</span> <span class="s1">&#39;hessFunction&#39;</span><span class="p">:</span> <span class="n">g1Hess</span><span class="p">})</span>
<span class="c1">#Initialize starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimisation problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimise</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>Just as in the previous case, the returned solution is dependent on the sample points, but it will be very close to the true optimal solution of <span class="math notranslate nohighlight">\(0\)</span> found at <span class="math notranslate nohighlight">\(x = [1,1]\)</span>.</p>
<p>The main benefit of using Effective Quadratures for optimisation is best realized in cases where derivatives are not known a priori or are very expensive to calculate. Such situations are commonplace in the scientific community e.g. for ‘black-box’ functions whose values are obtained through the use of expensive computer simulations. Derivative-free optimisation strategies, such as stochastic optimisation or Bayesian optimisation, may be used in such situations; however, these methods may not scale very well for problems of moderate to high dimension. On the other hand, using techniques available within Effective Quadratures, one can readily construct surrogate models of the function of interest using orthogonal polynomials and then optimise over the surrogate to approximate the optimal solution, even for high-dimensional functions.</p>
<p>To demonstrate this, we consider the following constrained optimisation problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\min_{\mathbf{x}}       \quad           &amp; \sum_{i=1}^n 3x_i^2 + 2x_i    \\
\textrm{ subject to }   &amp; \mathbf{x}^T \mathbf{x} \leq 4.
\end{eqnarray}\end{split}\]</div>
<p>Although, the gradients of these functions can be easily calculated analytically, we will show that if <a class="reference external" href="https://en.wikipedia.org/wiki/COBYLA">COBYLA</a> (a very common derivative-free optimisation strategy) is used, the number of function evaluations can be prohibitively high.</p>
<p>The new objective and constraint can be defined using the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ObjFun2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mf">3.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">ConFun2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">g</span>
</pre></div>
</div>
<p>We call SciPy implementation of COBYLA using the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">constraints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ConFun2</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mf">4.0</span><span class="p">}</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ObjFun2</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;COBYLA&#39;</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">)</span>
<span class="n">xopt</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ObjFun2</span><span class="p">(</span><span class="n">xopt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ConFun2</span><span class="p">(</span><span class="n">xopt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>On the other hand, both of these functions are sparse (i.e. most of the polynomial coefficients are zero), so we can use the <code class="code docutils literal notranslate"><span class="pre">compressive-sensing</span></code> method within Effective Quadratures to construct accurate surrogates and perform surrogate-based optimisation using the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">ObjFun2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">ConFun2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">fParameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">fpoly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">fParameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;compressive-sensing&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">f</span><span class="p">})</span>
<span class="n">fpoly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>

<span class="n">g2Parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">g2poly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">g2Parameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;compressive-sensing&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">g2</span><span class="p">})</span>
<span class="n">g2poly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>

<span class="c1">#Initialise optimization problem by specifying optimisation method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">Optimisation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">Poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g2poly &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;poly&#39;</span><span class="p">:</span> <span class="n">g2poly</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]})</span>
<span class="c1">#Solve optimisation problem</span>
<span class="n">sol2</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimise</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="n">xopt2</span> <span class="o">=</span> <span class="n">sol2</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">fopt2</span> <span class="o">=</span> <span class="n">sol2</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ObjFun2</span><span class="p">(</span><span class="n">xopt2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ConFun2</span><span class="p">(</span><span class="n">xopt2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol2</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">])</span>
</pre></div>
</div>
<table class="colwidths-given table" id="id2">
<caption><span class="caption-text">Optimisation results</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Optimisation strategy</p></th>
<th class="head"><p>Function evaluations</p></th>
<th class="head"><p>Solution</p></th>
<th class="head"><p>Constraint value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>COBYLA</p></td>
<td><p>551</p></td>
<td><p>-5.889</p></td>
<td><p>4.0</p></td>
</tr>
<tr class="row-odd"><td><p>Surrogate-based optimisation w/ EQ</p></td>
<td><p>150</p></td>
<td><p>-6.655</p></td>
<td><p>2.134</p></td>
</tr>
</tbody>
</table>
<p>The above table demonstrates the possible benefits of using Effective Quadratures for surrogate-based optimisation, as a better solution is obtained with far fewer function evaluations. It should be noted that the effectiveness of this approach is highly dependent on the accuracy of the surrogate models. In this rather contrived example, orthogonal polynomials defined over the domain of interest provide a very good approximation of the true function; however, in many other cases, this is not necessarily true. In these cases, we can use the <code class="code docutils literal notranslate"><span class="pre">trust-region</span></code> method within the <code class="code docutils literal notranslate"><span class="pre">Optimisation</span></code> class for bound-constrained optimisation problems.</p>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2016-2021 by Effective Quadratures.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>