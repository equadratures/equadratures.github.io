
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Higher order Sobol’ indices &#8212; equadratures</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/styles.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/footer.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/cards.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/fonts.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/eq-logo-favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo_new.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class=" collapse navbar-collapse">
    <div id="navbar-center" class="ml-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="research.html">
  Research
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="apps.html">
  Apps
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="developers.html">
  Developers
 </a>
</li>

    
    <li class="nav-item">
        <a class="nav-link nav-external" href="https://discourse.equadratures.org/">Discourse<i class="fas fa-external-link-alt"></i></a>
    </li>
    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search equadratures..." aria-label="Search equadratures..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="higher-order-sobol-indices">
<h1>Higher order Sobol’ indices<a class="headerlink" href="#higher-order-sobol-indices" title="Permalink to this headline">¶</a></h1>
<p>In certain cases, higher order output statistical indices may need to be estimated given input PDF. While first order statistics give the fractional variance conditioned on one variable at a time, the interactions between subsets of variables are neglected. Higher order Sobol’ indices address this particular issue.</p>
<p><strong>Theory</strong></p>
<p>Variances give the spread of the data away from the mean, but does not account for the direction of the spread and the relative weight of the tail of the distribution (the “peakiness”). The skewness and kurtosis address precisely these concerns. These measures can also be decomposed in a similar fashion to Sobol’ indices, giving rise to conditional skewness and kurtosis. Individual components to the skewness and kurtosis with respect to each input variable or groups of such may be computed using the new methods in the Statistics class.</p>
<p>The computation of Sobol’ indices is intuitive when considering the computation of the global variance using an orthogonal polynomial approximation of the function. Due to orthogonality of the basis polynomials, the global variance is computed as:</p>
<div class="math notranslate nohighlight">
\[\textrm{Var}[f(x)] = \sum_{i=1}^{P} \beta_i^2\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_i\)</span>’s are PC expansion coefficients, associated with a certain polynomial. A Sobol’ index simply sums up the squares of coefficients corresponding to contributing polynomials (i.e. polynomials with a non-zero order in the variables concerned). Conditional skewness/kurtosis indices follow the same principle.</p>
<p>Skewness and kurtosis are defined as the third and fourth central standardized moment. For instance, the skewness is:</p>
<div class="math notranslate nohighlight">
\[\mu^{3} = \int_S (f(x) - \mu)^{3} \rho ds = \int_S \left(\sum_{i=1}^P \beta_i \pi_i(x)\right)^{3} \rho ds,\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho\)</span> is the input PDF, defined over <span class="math notranslate nohighlight">\(S\)</span>, the support. In practice, Gauss quadrature is used to evaluate the integral numerically, and two approaches can be taken. First, one can sum the polynomial evaluations, each weighted by the corresponding coefficient at the quadrature points, resulting in a “total evaluation” at each quadrature point. Then, cube/fourth the results and compute the integral by forming the inner product with a quadrature weight vector. This approach is <span class="math notranslate nohighlight">\(O(Pd)\)</span> where <span class="math notranslate nohighlight">\(P\)</span> is the number of basis terms and <span class="math notranslate nohighlight">\(d\)</span> is the input dimension. This is satisfactory for computing the global skewness/kurtosis.</p>
<p>However, to compute conditional indices, it is necessary to expand the inner sum using the multinomial theorem first, as only by doing so will the result be interpretable as a sum of contributions from each  (group of) basis term(s) (effectively integral-before-sum). The details of such expansion is given in Geraci et al [1]. With computing the variance-based Sobol’ indices, the cross term conveniently cancels with orthogonality. However, with skewness and kurtosis the cross terms do not necessarily cancel. This necessitates an <span class="math notranslate nohighlight">\(O(P^3d)\)</span> operation for skewness and <span class="math notranslate nohighlight">\(O(P^4d)\)</span> operation for kurtosis, resulting in forbiddingly long computational times.</p>
<p>However, all is not lost, and some saving may be achieved with low order conditional skewness/kurtosis terms. First, Geraci et al.[1] details some conditions where the integral in the sum need not be computed as they are zero. Secondly, as only cross term integrals that result in the variables we are interested in need to be computed, some basis terms can be eliminated a priori. For instance, when computing first order indices, it is not necessary to consider any basis term that has total order larger than 1, since any integral with such a basis term will only increase the number of participating variables, and certainly will not contribute to the first order index at the end. This reduces the complexity to <span class="math notranslate nohighlight">\(O(n^3d)\)</span> for skewness, for example, where <span class="math notranslate nohighlight">\(n &lt;&lt; P\)</span> is the highest order of the polynomial in any dimension.</p>
<p><strong>Example</strong></p>
<p>Let’s see the methods in action. First we define a test function. Taking the quadratic G-function [1] as an example:</p>
<div class="math notranslate nohighlight">
\[f(x_0, x_1, x_2, x_3) = \prod_{i=1}^4 \frac{|4x_i - 2| + i^2}{1+i^2}.\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">G_fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">f</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span>
                <span class="n">f</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">t</span>
        <span class="k">return</span> <span class="n">f</span>
</pre></div>
</div>
<p>Let’s use a degree 5 tensor grid as the index set and the following input PDF:</p>
<div class="math notranslate nohighlight">
\[x_0, x_1, x_2, x_3 \sim \mathcal{U}(0,1)^4.\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">degree</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s2">&quot;Uniform&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span> <span class="o">=</span><span class="s2">&quot;Uniform&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span> <span class="o">=</span><span class="s2">&quot;Uniform&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span> <span class="o">=</span><span class="s2">&quot;Uniform&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">x3</span><span class="p">]</span>
</pre></div>
</div>
<p>Calculate the polynomial coefficients and initiate Statistics class:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">basis</span> <span class="o">=</span> <span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;Tensor grid&#39;</span><span class="p">)</span>
<span class="n">uqProblem</span> <span class="o">=</span> <span class="n">Polyint</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
<span class="n">uqProblem</span><span class="o">.</span><span class="n">computeCoefficients</span><span class="p">(</span><span class="n">G_fun</span><span class="p">)</span>
<span class="n">stats</span> <span class="o">=</span> <span class="n">uqProblem</span><span class="o">.</span><span class="n">getStatistics</span><span class="p">()</span>
</pre></div>
</div>
<p>By default, global indices (mean, variance, skewness and kurtosis) are already computed at initialization. They can be viewed through printing the corresponding class variables.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">mean</span>
<span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">variance</span>
<span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">skewness</span>
<span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span>

<span class="o">&gt;&gt;</span> <span class="mf">1.03619468893</span>
<span class="o">&gt;&gt;</span> <span class="mf">0.423001291441</span>
<span class="o">&gt;&gt;</span> <span class="mf">0.874198787521</span>
<span class="o">&gt;&gt;</span> <span class="mf">3.03775388049</span>
</pre></div>
</div>
<p>Now sample the output distribution with Monte Carlo and compute the statistics:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x0_samples</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">getSamples</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">x1_samples</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">getSamples</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">x2_samples</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">getSamples</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">x3_samples</span> <span class="o">=</span> <span class="n">x3</span><span class="o">.</span><span class="n">getSamples</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100000</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
        <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">G_fun</span><span class="p">([</span><span class="n">x0_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x2_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x3_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>

<span class="nb">print</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span> <span class="nb">float</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
<span class="nb">print</span> <span class="nb">float</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fisher</span> <span class="o">=</span> <span class="kc">False</span><span class="p">))</span>

<span class="o">&gt;&gt;</span> <span class="mf">1.0003033832</span>
<span class="o">&gt;&gt;</span> <span class="mf">0.471885570482</span>
<span class="o">&gt;&gt;</span> <span class="mf">0.688292325516</span>
<span class="o">&gt;&gt;</span> <span class="mf">2.92393148972</span>
</pre></div>
</div>
<p>As seen, the agreement is not bad. Now, let’s calculate the first two orders of conditional indices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">getSobol</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">getSobol</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">s1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">getCondSkewness</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">getCondSkewness</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">k1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">getCondKurtosis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">k2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">getCondKurtosis</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span> <span class="nb">sum</span><span class="p">(</span><span class="n">v1</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">v2</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s1</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s2</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span> <span class="nb">sum</span><span class="p">(</span><span class="n">k1</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">k2</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="o">&gt;&gt;</span> <span class="mf">0.999175600763</span>
<span class="o">&gt;&gt;</span> <span class="mf">0.962874587829</span>
<span class="o">&gt;&gt;</span> <span class="mf">0.89419000212</span>
</pre></div>
</div>
<p>As seen, the sums are close to one, so we don’t miss much by not evaluating the rest of the indices (which could take a long time). We may put these values in more context by calculating the Total Sensitivity Index [1] of each dimension:</p>
<div class="math notranslate nohighlight">
\[\textrm{TSI}^a_j = \sum_{\textbf{m}\in V_j} s^{SI}_\textbf{m}\]</div>
<p>where <span class="math notranslate nohighlight">\(V_j\)</span> denotes the set of multi-indices <span class="math notranslate nohighlight">\(\textbf{m}\)</span> that contains the dimension concerned, <span class="math notranslate nohighlight">\(j\)</span>. This can be applied to variance (<span class="math notranslate nohighlight">\(a=v\)</span>), skewness (<span class="math notranslate nohighlight">\(a=s\)</span>) and kurtosis (<span class="math notranslate nohighlight">\(a=k\)</span>). In our case, for example, we approximate:</p>
<div class="math notranslate nohighlight">
\[\textrm{TSI}^v_0 = \texttt{v1[(0)] + v2[(0,1)] + v2[(0,2)] + v2[(0,3)] }\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">calc_TSI</span><span class="p">([</span><span class="n">v1</span><span class="p">,</span><span class="n">v2</span><span class="p">])</span>
<span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">calc_TSI</span><span class="p">([</span><span class="n">s1</span><span class="p">,</span><span class="n">s2</span><span class="p">])</span>
<span class="nb">print</span> <span class="n">stats</span><span class="o">.</span><span class="n">calc_TSI</span><span class="p">([</span><span class="n">k1</span><span class="p">,</span><span class="n">k2</span><span class="p">])</span>

<span class="o">&gt;&gt;</span> <span class="p">[</span> <span class="mf">0.77715308</span>  <span class="mf">0.23639978</span>  <span class="mf">0.04004516</span>  <span class="mf">0.01008302</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="p">[</span> <span class="mf">0.90833698</span>  <span class="mf">0.66941268</span>  <span class="mf">0.12475714</span>  <span class="mf">0.03166169</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="p">[</span> <span class="mf">0.85915885</span>  <span class="mf">0.54439872</span>  <span class="mf">0.08897176</span>  <span class="mf">0.02198146</span><span class="p">]</span>
</pre></div>
</div>
<p>The results agree with the fact about the G-function, that the larger <span class="math notranslate nohighlight">\(i\)</span> is the lower the conditional index will be, and offers a quantitative measure of how important the variable is: the higher the index, the more important it is. This type of analysis can be applied to dimensional reduction applications to prune unnecessary variables. They also agree somewhat with Geraci et al. [1], but with some discrepancies (possibly due to the index set used).</p>
<p><strong>References</strong></p>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p>Geraci, G., Congedo, P. M., Abgrall, R., Iaccarino, G. (2016). High-order statistics in global sensitivity analysis: decomposition and model reduction. Computer Methods in Applied Mechanics and Engineering, 301, 80-115.</p>
</dd>
</dl>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer>
<div align="center"> 
<div class="logos">
<a href="https://github.com/Effective-Quadratures/Effective-Quadratures"><i class="fab fa-github"></i></a>   
<a href="https://effectivequadratures.slack.com/"><i class="fab fa-slack"></i></a>   
<a href="https://twitter.com/EQuadratures"><i class="fab fa-twitter"></i></a>   
<a href="https://discourse.equadratures.org"><i class="fab fa-discourse"></i></a>   
<a href="https://www.linkedin.com/company/effective-quadratures/about/"><i class="fab fa-linkedin"></i></a>   
<a href="https://www.youtube.com/channel/UCpjwFDSZuFbzW-2lj6d96dA"><i class="fab fa-youtube"></i></a>   
</div>

<span>Made by the Effective Quadratures Team, with ❤️</span>    
<span>Copyright © 2016-2021 by equadratures.org</span>    
<span> <a href="mailto:contact@equadratures.org">contact@equadratures.org</a> </span>   
</div>
</footer>
  </body>
</html>